{"cells": [{"metadata": {"id": "d37181ce-93a5-4397-8c11-2a9cb6d7ddc9"}, "cell_type": "markdown", "source": "# Create and Test Scoring Pipeline and Deploy R Shiny Dashboard App"}, {"metadata": {"id": "dddaeeda-e97b-433d-80b7-669cc8fbda40"}, "cell_type": "markdown", "source": "### Introduction\n\nNow that we have built the machine learning model, stored and deployed it, we can use the model to score new data. \n\nIn this notebook we will:\n\n* Programmatically get the ID's for the deployment space and model deployment that were created in the **`1_Model_Training`** notebook.\n* Promote assets required for scoring new data into the deployment space.\n* Create a deployable function which will take raw data for scoring, prep it into the format required for the model and score it.\n* Deploy the function..\n* Create the required payload, invoke the deployed function and return predictions. <br>\n\nIn the second part we will:\n\n* Store Shiny assets into the same deployment space.\n* Deploy Shiny assets as an app and view the dashboard."}, {"metadata": {"id": "6eb86b4d-8272-4266-ad6b-1b20c343dc9f"}, "cell_type": "markdown", "source": "**Sample Materials, provided under license. <br>\nLicensed Materials - Property of IBM. <br>\n\u00a9 Copyright IBM Corp. 2019, 2020. All Rights Reserved. <br>\nUS Government Users Restricted Rights - Use, duplication or disclosure restricted by GSA ADP Schedule Contract with IBM Corp. <br>**"}, {"metadata": {"id": "3e37f24b-0462-4358-874f-5241192d9b0f"}, "cell_type": "code", "source": "from statsmodels.tsa.arima_model import ARIMAResults\n\nimport os\nimport pandas as pd\nimport datetime\nfrom ibm_watson_machine_learning import APIClient\n\ntoken = os.environ['USER_ACCESS_TOKEN']\n\nwml_credentials = {\n   \"token\": token,\n   \"instance_id\" : \"openshift\",\n   \"url\": os.environ['RUNTIME_ENV_APSX_URL'],\n   \"version\": \"3.5\"\n}\n\nclient = APIClient(wml_credentials)", "execution_count": 1, "outputs": []}, {"metadata": {"id": "e0c0d794-b9a4-4236-9a7f-9585ee96d280"}, "cell_type": "markdown", "source": "### Set up Deployment Space, Deployments and Assets\n\nThe following code programmatically gets the deployment space and the model deployment details which were created in **1_Model_Training**. \nWe use the space name and default tags that were used when creating the deployments as specified below. \nIf multiple spaces with the same name exist, the code will take the space that was created most recently. Similarly, if multiple deployments within the selected space have the same tag, the most recently created deployment is used. \n\nAlternatively, the user can manually enter the space and deployment guid's.\n\nThe code also promotes some assets into the deployment space, specifically, the dataset with raw data for scoring, the python script file which is used for prepping the data and the metadata that was stored when prepping the data. By promoting these assets into the deployment space, they are available and can be accessed by the deployed function. "}, {"metadata": {"id": "5b1f3990-5265-4ba0-9fbe-c7b75ccb5d36"}, "cell_type": "code", "source": "space_name = 'effective_farming_model_space'\n", "execution_count": 2, "outputs": []}, {"metadata": {"id": "5943e388-0544-4ec2-b35a-40908b570270"}, "cell_type": "markdown", "source": "Get the space we are working in, which is found using the name that were hardcoded in **1_Model_Training**. If there are multiple spaces with the same name, we take the one that was created most recently. \n\nIf the user would like to use a different space manually set the **space_id**.\n\nSet the space as the default space for working."}, {"metadata": {"id": "b2ded105c0f4456a9bc6d5320ad66964"}, "cell_type": "code", "source": "for space in client.spaces.get_details()['resources']:\n\n    if space['entity']['name'] ==space_name:\n        print(\"Deployment space with \",space_name,\"already exists . .\")\n        space_uid=space['metadata']['id']\n        client.set.default_space(space_uid)", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "Deployment space with  effective_farming_model_space already exists . .\n", "name": "stdout"}]}, {"metadata": {"id": "06239478-7dec-4a73-b05c-3bd97e36d7d1"}, "cell_type": "markdown", "source": "### Promote Assets to Deployment space"}, {"metadata": {"id": "c3d485e3-ff76-4cf1-af52-adbcaec155db"}, "cell_type": "markdown", "source": "Promote the assets into the deployment space. We will use the prep script for getting the raw data into the format required for scoring. We also need the prep metadata that was saved as json during the prep for training, this ensures that the user inputs specified for prepping the data for training are the same used for scoring. We add these assets into the deployment space.  Also store the raw data dataset in the deployment space."}, {"metadata": {"id": "2d97c448-fdb4-4553-90d4-8496f0634115"}, "cell_type": "code", "source": "# we have four models corresponding to the 4 climate variables\nasset_temp = client.data_assets.create(name='arima_temp_model.json', file_path='/project_data/data_asset/arima_temp_model.json')\nasset_humidity = client.data_assets.create(name='arima_humidity_model.json', file_path='/project_data/data_asset/arima_humidity_model.json')\nasset_ws = client.data_assets.create(name='arima_ws_model.json', file_path='/project_data/data_asset/arima_ws_model.json')\nasset_precip = client.data_assets.create(name='arima_precip_model.json', file_path='/project_data/data_asset/arima_precip_model.json')", "execution_count": 4, "outputs": [{"output_type": "stream", "text": "Creating data asset...\nSUCCESS\nCreating data asset...\nSUCCESS\nCreating data asset...\nSUCCESS\nCreating data asset...\nSUCCESS\n", "name": "stdout"}]}, {"metadata": {"id": "c06669cd-fb7b-47c5-8ee2-fa47e7d470a3"}, "cell_type": "code", "source": "# Asset guid\nprint('Temperature Asset guid', asset_temp['metadata']['guid'])\nprint('Humidity Asset guid', asset_humidity['metadata']['guid'])\nprint('Wind Speed Asset guid', asset_ws['metadata']['guid'])\nprint('Precipitation Asset guid', asset_precip['metadata']['guid'])", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "Temperature Asset guid 451ca887-bd88-4401-9311-15b89e7095f6\nHumidity Asset guid 0e43d32c-3810-48c6-bf69-205cfed4b306\nWind Speed Asset guid 9e7e2e7a-af72-4bb8-ae53-4290534fad8c\nPrecipitation Asset guid 847c2356-3feb-4944-8fe7-03f36686d2c5\n", "name": "stdout"}]}, {"metadata": {"id": "f420e664-3cce-4738-ba32-fa728e5ea38d"}, "cell_type": "markdown", "source": "## Create the Deployable Function\n\nFunctions can be deployed in Watson Machine Learning in the same way models can be deployed. The python client or REST API can be used to send data to the deployed function. Using the deployed function allows us to prepare the data and pass it to the model for scoring all within the deployed function.\n\nWe start off by creating the dictionary of default parameters to be passed to the function. We get the ID's of all assets that have been promoted into the deployment space. We also add the model deployment ID and space ID information into the dictionary."}, {"metadata": {"id": "35e2b7d2-ebee-4657-a1cc-1e32ee7fec12"}, "cell_type": "code", "source": "# Metadata creation\nheader = {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + token}\nassets_dict = {'asset_temp_id' : asset_temp['metadata']['guid'], 'asset_temp_name' : 'arima_temp_model.json',\n               'asset_humidity_id' : asset_humidity['metadata']['guid'], 'asset_humidity_name' : 'arima_humidity_model.json', \n               'asset_ws_id' : asset_ws['metadata']['guid'], 'asset_ws_name' : 'arima_ws_model.json',\n               'asset_precip_id' : asset_precip['metadata']['guid'], 'asset_precip_name' : 'arima_precip_model.json',\n              }\nwml_credentials[\"instance_id\"] = \"openshift\"\nai_parms = {'wml_credentials' : wml_credentials,'header' : header, 'space_id' : space_uid, 'assets' : assets_dict}", "execution_count": 6, "outputs": []}, {"metadata": {"id": "f42ead10-d43c-46ab-8967-c05cac4dbd66"}, "cell_type": "markdown", "source": "### Scoring Pipeline Function\n\nThe function below takes 5 hours weather data and outputs next 5 hours weather. It prepares raw data, load model, execute model forecast and generate prediction for weather.\n\nThe following rules are required to make a valid deployable function:\n\n* The deployable function must include a nested function named \"score\".\n* The score function accepts a list.\n* The list must include an dictionary with the name \"values\". \"values\" include a dictionary with the name \"test_data\".\n* Scoring function returns a list with a dictionary key `predictions` and has two key-value pairs: `values` contains forecast weather values and `time` contains time of forecast.\n"}, {"metadata": {"id": "ef7416e128974e15b506126bb9aa77d2"}, "cell_type": "code", "source": "client.data_assets.download(ai_parms['assets']['asset_precip_id'], ai_parms['assets']['asset_precip_name'])", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "Successfully saved data asset content to file: 'arima_precip_model.json'\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 7, "data": {"text/plain": "'/home/wsuser/work/arima_precip_model.json'"}, "metadata": {}}]}, {"metadata": {"id": "fe39785fe2c14c4589109fc56d89df88"}, "cell_type": "code", "source": "loaded_model = ARIMAResults.load('/home/wsuser/work/arima_precip_model.json')", "execution_count": 8, "outputs": []}, {"metadata": {"id": "7adf7c21f04b48978030ee698350a0cd"}, "cell_type": "code", "source": "loaded_model.forecast(steps=5)", "execution_count": 9, "outputs": [{"output_type": "execute_result", "execution_count": 9, "data": {"text/plain": "2018-06-28 01:00:00    0.001263\n2018-06-28 02:00:00    0.001169\n2018-06-28 03:00:00    0.000960\n2018-06-28 04:00:00    0.000782\n2018-06-28 05:00:00    0.000637\nFreq: 60T, dtype: float64"}, "metadata": {}}]}, {"metadata": {"id": "0f778e20-575a-4616-b37b-6ed16a91d2a1"}, "cell_type": "code", "source": "def deploy_fn(parms=ai_parms):\n    \"\"\"\n        You will deploy this function.\n        -------------------------------\n        :return score function\n    \"\"\" \n    try:\n         \n        import subprocess\n        subprocess.check_output( \"pip install -I statsmodels==0.11.1 --user\", stderr=subprocess.STDOUT, shell=True)\n        import pandas as pd\n        import numpy as np\n        import json\n        import requests\n        import os\n\n        from statsmodels.tsa.statespace.sarimax import SARIMAX\n        from statsmodels.tsa.arima_model import ARIMAResults\n        \n        from ibm_watson_machine_learning import APIClient\n        client = APIClient(parms[\"wml_credentials\"])\n        client.set.default_space(parms['space_id'])\n    \n    except subprocess.CalledProcessError as e:\n    \n        return { \"error\" : \"subprocess.CalledProcessError:\\n\\n\" + \"cmd:\\n\" + e.cmd + \"\\n\\noutput:\\n\" + e.output.decode() }\n    \n    except Exception as e:\n    \n        return { \"error\" : repr( e ) }\n    \n    def score(payload):\n        \n        \n        # Temperature \n        forecast_value = []\n        forecast_period = [] \n        # Get all model paths\n        temp_model_path = client.data_assets.download(parms['assets']['asset_temp_id'], parms['assets']['asset_temp_name'])\n        humidity_model_path = client.data_assets.download(parms['assets']['asset_humidity_id'], parms['assets']['asset_humidity_name'])\n        ws_model_path = client.data_assets.download(parms['assets']['asset_ws_id'], parms['assets']['asset_ws_name'])\n        precip_model_path = client.data_assets.download(parms['assets']['asset_precip_id'], parms['assets']['asset_precip_name'])\n        \n        for i in [temp_model_path, humidity_model_path, ws_model_path, precip_model_path]:\n            # load the model\n            loaded_model = ARIMAResults.load(i)\n            # extend model if there is any past history data\n            if payload['input_data'][0]['values'][0] != 0:\n                input_data = pd.read_json(payload['input_data'][0]['values'][0])\n                input_data.index.freq = '60Min'\n                loaded_model = loaded_model.extend(input_data)\n            # forecast next 5-hour weather\n            result = loaded_model.forecast(steps=5)\n            for j in range(len(result)):\n                forecast_value.append(result[j])\n                forecast_period.append(str(result.index[j]))\n        # return response\n    \n        # score_response = {'predictions': [{ 'values': [['a']]}]} \n        return {'predictions': [{ 'values': [forecast_value], 'time': [forecast_period] }]}\n    return score", "execution_count": 10, "outputs": []}, {"metadata": {"id": "a5028827-a27e-45a7-8361-be23781d2452"}, "cell_type": "markdown", "source": "## Deploy the Function\n\nThe user can specify the name of the function and deployment in the code below. As we have previously seen, we use tags in the metadata to allow us to programmatically identify the deployed function. "}, {"metadata": {"id": "e54a4fa7-525f-437e-a0fb-a6ee91384728"}, "cell_type": "markdown", "source": "### Get the ID of software specification to be used with the function\n\nThe Software Specification refers to the runtime used in the Notebook, WML training and WML deployment. It contains details about the runtime platform, framework versions, other packages used and any custom library used in the concerned runtime.\n\nOur notebooks use the `default_py3.6` software specification. When we deploy our function we want it to have the same software specification as the notebooks. We get the ID of the notebook software specification and include it in the metadata when storing the function."}, {"metadata": {"id": "f354b1d4-5314-452a-8798-13d16d277361"}, "cell_type": "code", "source": "software_spec_id = client.software_specifications.get_uid_by_name(\"default_py3.7\")", "execution_count": 11, "outputs": []}, {"metadata": {"id": "f2fb1fbf-e24d-430c-ba8d-d6b239b10c63"}, "cell_type": "code", "source": "# Store function details\n\nmeta_data = {\n    client.repository.FunctionMetaNames.NAME : 'Function for predicting weather',\n    client.repository.FunctionMetaNames.TAGS : ['weather_function_tags'],\n    client.repository.FunctionMetaNames.SOFTWARE_SPEC_UID: software_spec_id\n\n}\n\nfunction_details = client.repository.store_function( meta_props=meta_data, function=deploy_fn)\n# Get function id\nfunction_id = function_details[\"metadata\"][\"id\"]", "execution_count": 12, "outputs": []}, {"metadata": {"id": "56e42bae-85d6-4b21-88eb-a8fdcab7dc55"}, "cell_type": "code", "source": "meta_props = {\n    client.deployments.ConfigurationMetaNames.NAME: 'complete model deployment',\n   client.deployments.ConfigurationMetaNames.TAGS : ['complete_forecast_function_deployment_tag'],\n    client.deployments.ConfigurationMetaNames.ONLINE: {}\n}\n\n# deploy the function\nfunction_deployment_details = client.deployments.create(artifact_uid=function_id, meta_props=meta_props)", "execution_count": 13, "outputs": [{"output_type": "stream", "text": "\n\n#######################################################################################\n\nSynchronous deployment creation for uid: '6d670556-0285-4df9-9a0e-edbed9c6811a' started\n\n#######################################################################################\n\n\ninitializing........\nready\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='7b4a1382-8bd6-443a-9058-d6e8b731e2b2'\n------------------------------------------------------------------------------------------------\n\n\n", "name": "stdout"}]}, {"metadata": {"id": "ae2199e9-223b-43c6-a0e2-1de9818a8743"}, "cell_type": "markdown", "source": "### Score New Data\n\nGet the guid of the deployed function, create the payload and use the python client to score the data. The deployed function returns the weather prediction. \n\nThe payload contains two values. The first is the effective date for scoring. This is the date that the prediction is computed. The scoring observation window and forecast horizon are calculated from this date. \nThe second value contains weather predictions. "}, {"metadata": {"id": "ce70c844-25ee-4ce8-9420-cfb3dad1d0b3"}, "cell_type": "code", "source": "scoring_deployment_id = client.deployments.get_uid(function_deployment_details)\nclient.deployments.get_details(scoring_deployment_id)", "execution_count": 14, "outputs": [{"output_type": "execute_result", "execution_count": 14, "data": {"text/plain": "{'entity': {'asset': {'id': '6d670556-0285-4df9-9a0e-edbed9c6811a'},\n  'custom': {},\n  'deployed_asset_type': 'function',\n  'hardware_spec': {'id': 'Not_Applicable', 'name': 'XXS', 'num_nodes': 1},\n  'name': 'complete model deployment',\n  'online': {},\n  'space_id': '9f809528-b691-4fe6-ae13-36411e5f0cdc',\n  'status': {'online_url': {'url': 'https://internal-nginx-svc:12443/ml/v4/deployments/7b4a1382-8bd6-443a-9058-d6e8b731e2b2/predictions'},\n   'state': 'ready'}},\n 'metadata': {'created_at': '2021-08-03T13:34:08.383Z',\n  'id': '7b4a1382-8bd6-443a-9058-d6e8b731e2b2',\n  'modified_at': '2021-08-03T13:34:08.383Z',\n  'name': 'complete model deployment',\n  'owner': '1000331209',\n  'space_id': '9f809528-b691-4fe6-ae13-36411e5f0cdc',\n  'tags': ['complete_forecast_function_deployment_tag']}}"}, "metadata": {}}]}, {"metadata": {"id": "9e3b691e327349d099bf9607d99006e4"}, "cell_type": "code", "source": "payload_scoring={\"input_data\": [{\"values\": [0]}]}\nprint(payload_scoring['input_data'][0]['values'][0])\n#payload_metadata = {client.deployments.ScoringMetaNames.INPUT_DATA: payload}\n# score\nfunct_output = client.deployments.score(scoring_deployment_id, payload_scoring)\nfunct_output", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "0\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 15, "data": {"text/plain": "{'predictions': [{'values': [[69.60014768188962,\n     69.39219749980322,\n     69.47374511323164,\n     69.8514987930284,\n     70.50145885728497,\n     100.78789643511031,\n     100.76381035226314,\n     99.92956415786254,\n     98.34218092237177,\n     96.10998673259584,\n     13.623792231063465,\n     13.32651551084038,\n     13.129206215966416,\n     12.918194955946312,\n     12.71351004756711,\n     0.0012627225856711448,\n     0.0011692884875361988,\n     0.0009597709082982593,\n     0.0007820719636892898,\n     0.0006369730205670305]],\n   'time': [['2018-06-28 01:00:00',\n     '2018-06-28 02:00:00',\n     '2018-06-28 03:00:00',\n     '2018-06-28 04:00:00',\n     '2018-06-28 05:00:00',\n     '2018-06-28 01:00:00',\n     '2018-06-28 02:00:00',\n     '2018-06-28 03:00:00',\n     '2018-06-28 04:00:00',\n     '2018-06-28 05:00:00',\n     '2018-06-28 01:00:00',\n     '2018-06-28 02:00:00',\n     '2018-06-28 03:00:00',\n     '2018-06-28 04:00:00',\n     '2018-06-28 05:00:00',\n     '2018-06-28 01:00:00',\n     '2018-06-28 02:00:00',\n     '2018-06-28 03:00:00',\n     '2018-06-28 04:00:00',\n     '2018-06-28 05:00:00']]}]}"}, "metadata": {}}]}, {"metadata": {"id": "d90193dc-4e3c-496c-b247-7e716736a9d9"}, "cell_type": "markdown", "source": "**The R Shiny Dashboard invokes this scoring pipeline for visualizing the results.***"}, {"metadata": {"id": "7331e298-e58b-47ee-aff3-cc94ada57465"}, "cell_type": "markdown", "source": "# Deploy Shiny App"}, {"metadata": {"id": "fec71699-462a-4096-be93-49bec6048157"}, "cell_type": "code", "source": "r_shiny_deployment_name='Effective_Farming_Shiny_App'", "execution_count": 16, "outputs": []}, {"metadata": {"id": "c287cc35-920d-4b88-842f-772541228edd"}, "cell_type": "markdown", "source": "### Store the App\n\nCreate the associated metadata and store the dashboard zip file in the deployment space. "}, {"metadata": {"id": "999ca15b-7309-4a56-ae3f-4f100d720b3e"}, "cell_type": "code", "source": "# Meta_props to store assets in space \nmeta_props = {\n    client.shiny.ConfigurationMetaNames.NAME: \"Effective_Farming_Shiny_Assets\",\n    client.shiny.ConfigurationMetaNames.DESCRIPTION: 'Store shiny assets in deployment space' # optional\n}\napp_details = client.shiny.store(meta_props, '/project_data/data_asset/effective-farming-monitor-crop-growth-dashboard.zip')", "execution_count": 17, "outputs": [{"output_type": "stream", "text": "Creating Shiny asset...\nSUCCESS\n", "name": "stdout"}]}, {"metadata": {"id": "a0e16d2f-6de6-4709-8bdc-36814ae878a9"}, "cell_type": "markdown", "source": "### Deploy the App\n\nCreate the metadata for the Shiny deployment by providing  name, description, R-Shiny options and Hardware specifications. R-Shiny configuration provides options on whom you want to share the dashboard with, they are: \n<br>\n* Anyone with the link \n* Authenticated users \n* Collaborators in this deployment space"}, {"metadata": {"id": "2a6bb611-9ff9-4938-9d3c-5cb35903d635"}, "cell_type": "code", "source": "# Deployment metadata.\ndeployment_meta_props = {\n    client.deployments.ConfigurationMetaNames.NAME: r_shiny_deployment_name,\n    client.deployments.ConfigurationMetaNames.DESCRIPTION: 'Deploy Effective Farming Dashboard',\n    client.deployments.ConfigurationMetaNames.R_SHINY: { 'authentication': 'anyone_with_url' },\n    client.deployments.ConfigurationMetaNames.HARDWARE_SPEC: { 'name': 'S', 'num_nodes': 1}\n}\n\n\n# Create the deployment.\napp_uid = client.shiny.get_uid(app_details)\nrshiny_deployment = client.deployments.create(app_uid, deployment_meta_props)", "execution_count": 18, "outputs": [{"output_type": "stream", "text": "\n\n#######################################################################################\n\nSynchronous deployment creation for uid: '7da91310-6490-40f9-8acc-cd4213547f68' started\n\n#######################################################################################\n\n\ninitializing......\nready\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='54a082b8-5c4e-4aeb-bbf7-088ac625f1e5'\n------------------------------------------------------------------------------------------------\n\n\n", "name": "stdout"}]}, {"metadata": {"id": "f7e58bcc-b422-4276-bc58-091a0824d9be"}, "cell_type": "markdown", "source": "### Launch Shiny App\nNow that the dashboard is deployed, it can be accessed through the web browser. The app URL can be found by navigating to the deployed app in the deployment space. \n\nOpen the Navigation Menu, under ***Analytics*** select ***Analytics deployments -> effective_farming_model_space -> Deployments -> Effective_Farming_Shiny_Assets*** to find the dashboard URL.\n\nAlternatively, the path for the app URL can be found from the deployment metadata created in the previous cell. This path should be appended to the user's Cloud Pak for Data hostname to get the complete app URL. To get the path, run the cell below:"}, {"metadata": {"id": "ec86267e-94c1-4cc4-9d6f-36d6daf357e9"}, "cell_type": "code", "source": "print(\"{HOSTNAME}\"+\"/ml/v4/deployments/\"+rshiny_deployment['metadata']['id'] + '/r_shiny')\n", "execution_count": 19, "outputs": [{"output_type": "stream", "text": "{HOSTNAME}/ml/v4/deployments/54a082b8-5c4e-4aeb-bbf7-088ac625f1e5/r_shiny\n", "name": "stdout"}]}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}