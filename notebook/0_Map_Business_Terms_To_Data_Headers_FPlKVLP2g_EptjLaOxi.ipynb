{"cells": [{"metadata": {"id": "9b0050f3-b6d6-4788-86e7-df36633d7d0b"}, "cell_type": "markdown", "source": "# Map Business Terms to Data Headers"}, {"metadata": {"id": "66d91e28-6cb5-4bf6-8536-790019205dcf"}, "cell_type": "markdown", "source": "## Introduction\n\nIn this notebook we programmatically publish a dataset into a catalog and map business terms to the dataset column headers. The business terms and their mappings are specified in a csv file included with the project. \n\nThis notebook is optional. The analytics project runs as expected even if this notebook is not used. \n\n**Note that as only Admin users can import terms, this notebook should be run by an Admin user only.**"}, {"metadata": {"id": "dd23cc91-3a2d-4af3-96ac-a2a3d48150b1"}, "cell_type": "markdown", "source": "**This project contains Sample Materials, provided under license. <br>\nLicensed Materials - Property of IBM. <br>\n\u00a9 Copyright IBM Corp. 2019, 2020. All Rights Reserved. <br>\nUS Government Users Restricted Rights - Use, duplication or disclosure restricted by GSA ADP Schedule Contract with IBM Corp.<br>**"}, {"metadata": {"id": "ff598c3e-431b-4643-a564-caae5b823a02"}, "cell_type": "markdown", "source": "## Prerequisites\n\n### Create Category and Sub-category\n\nNaviagte to Governance -> Categories -> New category -> Provide name of the category -> Under `Subcategories`, click on `Create category` -> Provide name of the subcategory -> Note both category and sub-category names\n\nExample: If you create category as `Category_main` and subcategory as `Category_sub`, you need to make sure the following in `customer-segmentation-glossary-terms.csv` file.\n\n- Column `Category` has path as `Category_main >> Category_sub`.\n- Column `Part of Terms` has `Category_main >> Category_sub` path before the terms name.\n\n\n### Upload Business Terms File\n\nBusiness term mapping is provided in the file `customer-segmentation-glossary-terms.csv`. \n\nNavigate to Governance -> Business terms -> Add business term -> Import from file -> Click on `Add file` -> Upload the file -> Publish\n\n\n### Create Catalog\n\nNavigate to catalog -> All Catalogs -> Create Catalog -> Enter the name for the new catalog and the description if necessary and create the catalog. \n\nIf the user has already created the catalog this step can be skipped and the existing catalog name should be specified in the code cell below."}, {"metadata": {"id": "7103b420-ee45-4bc2-acd3-76f2b088fd51"}, "cell_type": "code", "source": "# imports for the rest APIs interactions with WKC\nimport requests\nfrom requests.packages.urllib3.exceptions import InsecureRequestWarning\nimport json\nrequests.packages.urllib3.disable_warnings(InsecureRequestWarning)\nfrom pandas.io.json import json_normalize\nimport pandas as pd\nimport os\n\n# use this library for reading and saving data in CP4D\nfrom project_lib import Project\nproject = Project()", "execution_count": 1, "outputs": []}, {"metadata": {"id": "a157e826-eca4-4184-8040-a0f4ee799d24"}, "cell_type": "markdown", "source": "## User Inputs\n\nThe user must enter the following before running the rest of the notebook: \n1. **host :** host url of the cluster we are working on.\n2. **catalog_name :** Name of the catalog that we would like to publish the csv to. This catalog is created based on the instructions above or an existing catalog.\n3. **category_name :** Name of the business term category corresponding to the project. This catalog is created based on the instructions above or an existing category."}, {"metadata": {"id": "268c4c50-6ab9-416b-9004-249b17fc947f"}, "cell_type": "markdown", "source": "We also create additional variables. The user does not need to change the code cell below, unless they change the business terms category name or the name of the csv file with mappings.\n\n1. **terms_file :** Name of the csv file containing the list of mappings between column headers and business terms.\n2. **csv_file_to_publish :** Name of the csv files that will be published into the catalog and for which we map business terms."}, {"metadata": {"id": "2661d9abbee741528b725a1d4a88da83"}, "cell_type": "code", "source": "import os\naccessToken = os.environ['USER_ACCESS_TOKEN']\nhost = 'https://********.com/'\n# For example, you can customize the catalog_name as 'Industry Accelerators'\ncatalog_name = 'Industry Accelerators'\n# Customize the category_name as 'Effective Farming - Monitor Crop Growth'\ncategory_name = 'Effective Farming - Monitor Crop Growth'", "execution_count": 2, "outputs": []}, {"metadata": {"id": "ea5aa085-0a0c-4afb-9557-c32cccbd4da4"}, "cell_type": "code", "source": "terms_file = \"effective-farming-monitor-crop-growth-map-terms.csv\" \ncsv_file_to_publish = ['jfk_weather.csv']", "execution_count": 3, "outputs": []}, {"metadata": {"id": "e7bb9f86-9812-44aa-96f5-e7fb3fd1924e"}, "cell_type": "markdown", "source": "Create a requests session and use the same session throughout the notebook. "}, {"metadata": {"id": "90414d8b-7d4b-4aee-a573-e703012fad15"}, "cell_type": "code", "source": "# Creates requests session and stores in `s`\ns = requests.Session()", "execution_count": 4, "outputs": []}, {"metadata": {"id": "e5f26410-303b-4417-b02f-7c5d126e9589"}, "cell_type": "markdown", "source": "## Authentication"}, {"metadata": {"id": "3779fdfe-6a55-456d-aba4-aab0ac4dee0a"}, "cell_type": "markdown", "source": "Generate a token and validate the token on this cluster."}, {"metadata": {"id": "4fb173160ef94d9195fcc6d05793d08f"}, "cell_type": "code", "source": "accessToken = os.environ['USER_ACCESS_TOKEN']", "execution_count": 5, "outputs": []}, {"metadata": {"id": "def4f344-6684-4889-8d69-a5818652c7bf"}, "cell_type": "markdown", "source": "## Map Business Terms to Headers\n\nWe complete the following steps to map the business terms to column headers:\n\n1. Check if the Category, `Effective Farming - Monitor Crop Growth`, exists in the parent category `Industry Accelerators`.\n2. Load the business terms from the `Effective Farming - Monitor Crop Growth` subcategory into a dataframe.\n3. Publish the specified dataset into the catalog.\n4. Assign business terms to the dataset column headers."}, {"metadata": {"id": "ba3a951f-f96e-4b87-998f-9f4a74776a2f"}, "cell_type": "markdown", "source": "### 1. Check for the Category"}, {"metadata": {"id": "158e34cf-d227-44db-9fa2-f3be23f4778e"}, "cell_type": "markdown", "source": "Below cell fetches all the categories present in the cluster and stores category id of the category `Effective Farming - Monitor Crop Growth`."}, {"metadata": {"id": "7b71e83f769c4478ac5e6874cbdcf6a9"}, "cell_type": "code", "source": "search_url=host+\"v3/search\"\ntry:\n    headers = {\n        'Content-Type': \"application/json\",\n        'Authorization': \"Bearer \"+accessToken,\n        'Cache-Control': \"no-cache\",\n        'Connection': \"keep-alive\"\n        }\n    \n    search_body = {\n        \"size\": 1000,\n        \"_source\": [\"artifact_id\",\"metadata.name\"],\n       \"query\": {    \n               \"match\": {\"metadata.artifact_type\": \"category\"}\n       }\n    }\n    parent_cat = s.post(search_url, verify=False,  json=search_body, headers=headers)\n    # Check if Industry accelerator category exists and load its id into a variable `parent_id`\n    if parent_cat.status_code == 200:\n        category=json.loads(parent_cat.text)\n        for i in category['rows']:\n            if i['metadata']['name']== category_name:\n                print(\"Category \",category_name,\"exists\")\n                exists_category=True\n                category_id=i['artifact_id'] \n            \n                   \nexcept:\n    print(\"The below error has occurred. \" + \"Please ensure that category, '\" + category_name + \"', exists.\")\n    raise ValueError(parent_cat.text)", "execution_count": 6, "outputs": [{"name": "stdout", "text": "Category  Effective Farming - Monitor Crop Growth exists\n", "output_type": "stream"}]}, {"metadata": {"id": "b6efc78d-86bf-4744-b050-5a3ef0f6d081"}, "cell_type": "markdown", "source": "### 2. Load Subcategory Business Terms into Dataframe "}, {"metadata": {"id": "aeeebcdd-6240-477b-be9d-94b2137882e5"}, "cell_type": "markdown", "source": "Get all of the terms in the `Effective Farming - Monitor Crop Growth` subcategory and store them in the `df_terms` dataframe."}, {"metadata": {"id": "addbf711b41c40cc8865f654b907d0dc"}, "cell_type": "code", "source": "# Create a payload for the post request, This payload contains information on size of the terms, source, category and subcategory ids\npayload={\"size\":300,\"from\":0,\"_source\":[\"artifact_id\",\"metadata.artifact_type\",\"metadata.name\",\"metadata.description\",\"categories\",\"entity.artifacts\"],\"query\":{\"bool\":{\"filter\":{\"bool\":{\"minimum_should_match\":1,\"should\":[{\"term\":{\"categories.primary_category_id\":category_id}},{\"term\":{\"categories.secondary_category_ids\":category_id}}],\"must_not\":{\"terms\":{\"metadata.artifact_type\":[\"category\"]}}}}}}}\n# create a post request with above payload \nwf=s.post(host+\"v3/search\",headers=headers,json=payload,verify=False)\n# it will return all the terms , load these terms into a dataframe\nwf_json=json.loads(wf.text)['rows']\ndf_terms=pd.json_normalize(wf_json)\ndf_terms.head()", "execution_count": 7, "outputs": [{"data": {"text/plain": "                            artifact_id  _score metadata.artifact_type  \\\n0  a6e251fc-0426-4f3e-9395-1838c1fd2b82     0.0          glossary_term   \n1  eb701c21-d63d-4a43-834c-36ca03c98ec2     0.0          glossary_term   \n2  75578dbd-fbac-435b-957b-75befa6ae1a2     0.0          glossary_term   \n3  eee35fbb-4f81-44b7-a760-fafb0ab831d6     0.0          glossary_term   \n4  88822638-585c-4b62-9f10-bce52be0ecf3     0.0          glossary_term   \n\n                  metadata.name          metadata.description  \\\n0                 DAILYSnowfall                 DAILYSnowfall   \n1          MonthlyTotalSnowfall          MonthlyTotalSnowfall   \n2  MonthlyGreatestSnowDepthDate  MonthlyGreatestSnowDepthDate   \n3            MonthlyMinimumTemp            MonthlyMinimumTemp   \n4                     LONGITUDE                     LONGITUDE   \n\n  categories.secondary_category_ids  categories.last_updated_at  \\\n0                                []               1627959056757   \n1                                []               1627959061741   \n2                                []               1627959061500   \n3                                []               1627959062056   \n4                                []               1627959062837   \n\n  categories.secondary_category_global_ids  \\\n0                                       []   \n1                                       []   \n2                                       []   \n3                                       []   \n4                                       []   \n\n               categories.primary_category_global_id  \\\n0  5d2d5419-0032-4c64-90e2-ce68c6997bb5_df55cd18-...   \n1  5d2d5419-0032-4c64-90e2-ce68c6997bb5_df55cd18-...   \n2  5d2d5419-0032-4c64-90e2-ce68c6997bb5_df55cd18-...   \n3  5d2d5419-0032-4c64-90e2-ce68c6997bb5_df55cd18-...   \n4  5d2d5419-0032-4c64-90e2-ce68c6997bb5_df55cd18-...   \n\n         categories.primary_category_id  \\\n0  df55cd18-d85e-46b5-9e82-80b3031e7367   \n1  df55cd18-d85e-46b5-9e82-80b3031e7367   \n2  df55cd18-d85e-46b5-9e82-80b3031e7367   \n3  df55cd18-d85e-46b5-9e82-80b3031e7367   \n4  df55cd18-d85e-46b5-9e82-80b3031e7367   \n\n          categories.primary_category_name  \\\n0  Effective Farming - Monitor Crop Growth   \n1  Effective Farming - Monitor Crop Growth   \n2  Effective Farming - Monitor Crop Growth   \n3  Effective Farming - Monitor Crop Growth   \n4  Effective Farming - Monitor Crop Growth   \n\n  categories.secondary_category_names entity.artifacts.synonym_global_ids  \\\n0                                  []                                  []   \n1                                  []                                  []   \n2                                  []                                  []   \n3                                  []                                  []   \n4                                  []                                  []   \n\n  entity.artifacts.synonyms  \\\n0                        []   \n1                        []   \n2                        []   \n3                        []   \n4                        []   \n\n                          entity.artifacts.global_id  \\\n0  5d2d5419-0032-4c64-90e2-ce68c6997bb5_a6e251fc-...   \n1  5d2d5419-0032-4c64-90e2-ce68c6997bb5_eb701c21-...   \n2  5d2d5419-0032-4c64-90e2-ce68c6997bb5_75578dbd-...   \n3  5d2d5419-0032-4c64-90e2-ce68c6997bb5_eee35fbb-...   \n4  5d2d5419-0032-4c64-90e2-ce68c6997bb5_88822638-...   \n\n  entity.artifacts.effective_start_date  \\\n0              2021-08-03T02:50:42.410Z   \n1              2021-08-03T02:50:42.409Z   \n2              2021-08-03T02:50:42.404Z   \n3              2021-08-03T02:50:42.412Z   \n4              2021-08-03T02:50:42.410Z   \n\n              entity.artifacts.version_id entity.artifacts.abbreviation  \\\n0  2c4ae536-769c-4eb6-af74-b53b644d179e_0                            []   \n1  8a4fdaad-b218-4703-9620-f3cd01211ad8_0                            []   \n2  80951194-d889-4772-94c2-5763db6260ed_0                            []   \n3  955e24c1-9ba7-4e19-bb08-195911fbb332_0                            []   \n4  a7618894-b360-43cb-b0fd-44f57f80bf6e_0                            []   \n\n           entity.artifacts.artifact_id  \n0  a6e251fc-0426-4f3e-9395-1838c1fd2b82  \n1  eb701c21-d63d-4a43-834c-36ca03c98ec2  \n2  75578dbd-fbac-435b-957b-75befa6ae1a2  \n3  eee35fbb-4f81-44b7-a760-fafb0ab831d6  \n4  88822638-585c-4b62-9f10-bce52be0ecf3  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>artifact_id</th>\n      <th>_score</th>\n      <th>metadata.artifact_type</th>\n      <th>metadata.name</th>\n      <th>metadata.description</th>\n      <th>categories.secondary_category_ids</th>\n      <th>categories.last_updated_at</th>\n      <th>categories.secondary_category_global_ids</th>\n      <th>categories.primary_category_global_id</th>\n      <th>categories.primary_category_id</th>\n      <th>categories.primary_category_name</th>\n      <th>categories.secondary_category_names</th>\n      <th>entity.artifacts.synonym_global_ids</th>\n      <th>entity.artifacts.synonyms</th>\n      <th>entity.artifacts.global_id</th>\n      <th>entity.artifacts.effective_start_date</th>\n      <th>entity.artifacts.version_id</th>\n      <th>entity.artifacts.abbreviation</th>\n      <th>entity.artifacts.artifact_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a6e251fc-0426-4f3e-9395-1838c1fd2b82</td>\n      <td>0.0</td>\n      <td>glossary_term</td>\n      <td>DAILYSnowfall</td>\n      <td>DAILYSnowfall</td>\n      <td>[]</td>\n      <td>1627959056757</td>\n      <td>[]</td>\n      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_df55cd18-...</td>\n      <td>df55cd18-d85e-46b5-9e82-80b3031e7367</td>\n      <td>Effective Farming - Monitor Crop Growth</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_a6e251fc-...</td>\n      <td>2021-08-03T02:50:42.410Z</td>\n      <td>2c4ae536-769c-4eb6-af74-b53b644d179e_0</td>\n      <td>[]</td>\n      <td>a6e251fc-0426-4f3e-9395-1838c1fd2b82</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>eb701c21-d63d-4a43-834c-36ca03c98ec2</td>\n      <td>0.0</td>\n      <td>glossary_term</td>\n      <td>MonthlyTotalSnowfall</td>\n      <td>MonthlyTotalSnowfall</td>\n      <td>[]</td>\n      <td>1627959061741</td>\n      <td>[]</td>\n      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_df55cd18-...</td>\n      <td>df55cd18-d85e-46b5-9e82-80b3031e7367</td>\n      <td>Effective Farming - Monitor Crop Growth</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_eb701c21-...</td>\n      <td>2021-08-03T02:50:42.409Z</td>\n      <td>8a4fdaad-b218-4703-9620-f3cd01211ad8_0</td>\n      <td>[]</td>\n      <td>eb701c21-d63d-4a43-834c-36ca03c98ec2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>75578dbd-fbac-435b-957b-75befa6ae1a2</td>\n      <td>0.0</td>\n      <td>glossary_term</td>\n      <td>MonthlyGreatestSnowDepthDate</td>\n      <td>MonthlyGreatestSnowDepthDate</td>\n      <td>[]</td>\n      <td>1627959061500</td>\n      <td>[]</td>\n      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_df55cd18-...</td>\n      <td>df55cd18-d85e-46b5-9e82-80b3031e7367</td>\n      <td>Effective Farming - Monitor Crop Growth</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_75578dbd-...</td>\n      <td>2021-08-03T02:50:42.404Z</td>\n      <td>80951194-d889-4772-94c2-5763db6260ed_0</td>\n      <td>[]</td>\n      <td>75578dbd-fbac-435b-957b-75befa6ae1a2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>eee35fbb-4f81-44b7-a760-fafb0ab831d6</td>\n      <td>0.0</td>\n      <td>glossary_term</td>\n      <td>MonthlyMinimumTemp</td>\n      <td>MonthlyMinimumTemp</td>\n      <td>[]</td>\n      <td>1627959062056</td>\n      <td>[]</td>\n      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_df55cd18-...</td>\n      <td>df55cd18-d85e-46b5-9e82-80b3031e7367</td>\n      <td>Effective Farming - Monitor Crop Growth</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_eee35fbb-...</td>\n      <td>2021-08-03T02:50:42.412Z</td>\n      <td>955e24c1-9ba7-4e19-bb08-195911fbb332_0</td>\n      <td>[]</td>\n      <td>eee35fbb-4f81-44b7-a760-fafb0ab831d6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>88822638-585c-4b62-9f10-bce52be0ecf3</td>\n      <td>0.0</td>\n      <td>glossary_term</td>\n      <td>LONGITUDE</td>\n      <td>LONGITUDE</td>\n      <td>[]</td>\n      <td>1627959062837</td>\n      <td>[]</td>\n      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_df55cd18-...</td>\n      <td>df55cd18-d85e-46b5-9e82-80b3031e7367</td>\n      <td>Effective Farming - Monitor Crop Growth</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>5d2d5419-0032-4c64-90e2-ce68c6997bb5_88822638-...</td>\n      <td>2021-08-03T02:50:42.410Z</td>\n      <td>a7618894-b360-43cb-b0fd-44f57f80bf6e_0</td>\n      <td>[]</td>\n      <td>88822638-585c-4b62-9f10-bce52be0ecf3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}, "execution_count": 7, "output_type": "execute_result"}]}, {"metadata": {"id": "05781269303947da909240afa6e8ad70"}, "cell_type": "code", "source": "payload", "execution_count": 8, "outputs": [{"data": {"text/plain": "{'size': 300,\n 'from': 0,\n '_source': ['artifact_id',\n  'metadata.artifact_type',\n  'metadata.name',\n  'metadata.description',\n  'categories',\n  'entity.artifacts'],\n 'query': {'bool': {'filter': {'bool': {'minimum_should_match': 1,\n     'should': [{'term': {'categories.primary_category_id': 'df55cd18-d85e-46b5-9e82-80b3031e7367'}},\n      {'term': {'categories.secondary_category_ids': 'df55cd18-d85e-46b5-9e82-80b3031e7367'}}],\n     'must_not': {'terms': {'metadata.artifact_type': ['category']}}}}}}}"}, "metadata": {}, "execution_count": 8, "output_type": "execute_result"}]}, {"metadata": {"id": "57bd3510-e4e9-479c-a328-7c10e007b359"}, "cell_type": "markdown", "source": "### 3. Publish Dataset into Catalog"}, {"metadata": {"id": "dcb120e4-539b-4789-abbd-fae65498b615"}, "cell_type": "markdown", "source": "Get the ID of the catalog that was specified in the user inputs at the beginning of this notebook."}, {"metadata": {"id": "29884f51-0f1a-4812-85b9-4112ac28f4c0"}, "cell_type": "code", "source": "## Get catalog that created and its id by providing name of the catalog created, wich should be same as the one entered in the previous cells\ncatalog_endpoint=host+\"v2/catalogs\"\n# Create new header for the requests\nheaders = {\n'Content-Type': \"application/json\",\n'Authorization': \"Bearer \"+accessToken\n\n}\n\n# endpoint to get all the catalogs \nget_catalog=s.get(catalog_endpoint,verify=False, headers=headers)\n\n\n## Find the catalog created with specific name and store name and id of it into catalog_name and catalog_id respectively\ntry:\n    get_catalog_json=json.loads(get_catalog.text)['catalogs']\nexcept:\n    print(\"The below error has occurred. Please ensure that catalog, '\" + catalog_name + \"', exists\")\n    raise\n    \ncatalog_id = ''\nfor metadata in get_catalog_json:\n    if metadata['entity']['name']==catalog_name:\n        catalog_id=metadata['metadata']['guid']\n        print(\"catalog_id for\",catalog_name, catalog_id)\n\nif catalog_id == '':\n    print(\"The provided catalog name cannot be found. Please ensure that catalog, '\" + catalog_name + \"', exists\")\n    raise ValueError(\"Catalog cannot be found\")", "execution_count": 9, "outputs": [{"name": "stdout", "text": "catalog_id for Industry Accelerators 1aef8835-531c-41fa-8dff-4a67f7619aa5\n", "output_type": "stream"}]}, {"metadata": {"id": "03ecc695-a4c6-4421-a087-0dc2237d3322"}, "cell_type": "markdown", "source": "Get the project id. All project assets can be accessed using this project id."}, {"metadata": {"id": "87856a58-5ecd-40ce-8f2d-4ab96322ac30"}, "cell_type": "code", "source": "project_id=os.environ['PROJECT_ID']", "execution_count": 10, "outputs": []}, {"metadata": {"id": "a41ccbcb-02be-4d81-adf7-94317eac7fcb"}, "cell_type": "markdown", "source": "Get all existing csv files in the project folder and store the names of these files. "}, {"metadata": {"id": "148fd14e-5032-43f6-bab7-a9deb5f396a9"}, "cell_type": "code", "source": "# payload \npayload={\"query\":\"*:*\",\"limit\":200}\n# endpoint to access all the project assets in the project folder \nasset_url=host+\"/v2/asset_types/asset/search?project_id=\"+project_id\nget_asset=s.post(asset_url,json=payload,verify=False)", "execution_count": 11, "outputs": []}, {"metadata": {"id": "30bd3ca6-b776-492e-b0cb-f3f3f3db23bc"}, "cell_type": "markdown", "source": "Next we get the asset id of the dataset to be published to the catalog."}, {"metadata": {"id": "fbc0539f-c59b-47f2-8dd7-329116e8a325"}, "cell_type": "code", "source": "# Get asset ids of all csv files to be published in to the catalog and store the asset ids in an array\n\nproject_asset_id=[]\n# Payload to query all project assets\npayload={\"query\":\"*:*\",\"limit\":200}\n\nget_asset=s.post(host+\"v2/asset_types/asset/search?project_id=\"+project_id,json=payload,verify=False, headers=headers)\nget_asset_json=json.loads(get_asset.text)\nfor j in get_asset_json['results']:\n    if j['metadata']['name'] in csv_file_to_publish:\n        print(\"Asset id of\",j['metadata']['name'],\":\",j['metadata']['asset_id'])\n        project_asset_id.append(j['metadata']['asset_id'])", "execution_count": 12, "outputs": [{"name": "stdout", "text": "Asset id of jfk_weather.csv : a4ced745-9f85-429d-9d2b-3070860401db\n", "output_type": "stream"}]}, {"metadata": {"id": "8036e051531e4bb6aaae5231d75906e5"}, "cell_type": "markdown", "source": "### Search if the catalog already has the asset. Delete existing similar asset before publishing"}, {"metadata": {"id": "e31585c42e7e44e98ca8a4b2fbea70c5"}, "cell_type": "code", "source": "# Search for list of assets in the catalog\nasset_list_in_catalog = s.post(host+\"v2/asset_types/asset/search?catalog_id=\"+catalog_id,json=payload,verify=False, headers=headers)\n# Store the result in json\nasset_list_result = json.loads(asset_list_in_catalog.text)\nfor result in asset_list_result['results']:\n    # Get asset name\n    if result['metadata']['name'] in csv_file_to_publish:\n        # Get the asset id\n        retrieve_asset_id = result['metadata']['asset_id']\n        # Delete the asset\n        asset_to_delete_url=host+\"v2/assets/\"+retrieve_asset_id+\"?catalog_id=\"+catalog_id\n        delete_result=requests.delete(asset_to_delete_url,headers=headers,verify=False)", "execution_count": 13, "outputs": []}, {"metadata": {"id": "32431d3371f34f6480a99d443f6efab3"}, "cell_type": "markdown", "source": "### Publish Asset to the Catalog"}, {"metadata": {"id": "d7b2c676-6adf-4ef3-bc1d-d1188809dd3c"}, "cell_type": "markdown", "source": "Using the asset ID for the dataset, upload the dataset into the catalog using the post request below. Get the new asset ID of the newly published dataset."}, {"metadata": {"id": "c0c0e908-ecfe-4528-a1a6-94ffb2b1d0ca"}, "cell_type": "code", "source": "print(\"ASSET ID's of the published assets\")\n# Creates a empty dictionary\ncatalog_asset_ids={}\nfor asset_id in project_asset_id:\n    #for  each asset in the project , publish them into the catalog \n    # pyload to publish the asset\n    payload={\"mode\":0,\"catalog_id\":catalog_id,\"metadata\":{}}\n    # endpoint to publish asset\n    asset_publish_url=host+\"v2/assets/\"+asset_id+\"/publish?project_id=\"+project_id\n    # Post request with endpoint, heaeder and payload\n    publishasset=requests.post(asset_publish_url,json=payload,headers=headers,verify=False)\n    # api endpoint returns below text\n    publishasset_json=json.loads(publishasset.text)\n    # extract csv file published and its asset id and append it to the dictionary\n    catalog_asset_ids[publishasset_json['metadata']['name']]=publishasset_json['asset_id']\n    \nprint(catalog_asset_ids)", "execution_count": 14, "outputs": [{"name": "stdout", "text": "ASSET ID's of the published assets\n{'jfk_weather.csv': '2d6e622c-9d85-4798-993a-7a415a54a37d'}\n", "output_type": "stream"}]}, {"metadata": {"id": "2d10ee1f-60f4-4f3f-8b95-e76a2b8da3b7"}, "cell_type": "markdown", "source": "### 4. Assign Business Terms to Column Headers\n\nRead in the file with business terms and their associated column headers and view a sample of the data."}, {"metadata": {"id": "1c0b6944-cafb-4c59-9eaa-6423ecafa478"}, "cell_type": "code", "source": "map_terms_file = project.get_file(terms_file)\nmap_terms_file.seek(0)\nmap_terms = pd.read_csv(map_terms_file)", "execution_count": 15, "outputs": []}, {"metadata": {"id": "c56ed403-0e98-43f3-9dca-b0660c720cd4"}, "cell_type": "code", "source": "print(map_terms.shape)\nmap_terms.head()", "execution_count": 16, "outputs": [{"name": "stdout", "text": "(90, 3)\n", "output_type": "stream"}, {"data": {"text/plain": "  Business Terms Column_header         File\n0        STATION       STATION  jfk_weather\n1   STATION_NAME  STATION_NAME  jfk_weather\n2      ELEVATION     ELEVATION  jfk_weather\n3       LATITUDE      LATITUDE  jfk_weather\n4      LONGITUDE     LONGITUDE  jfk_weather", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Business Terms</th>\n      <th>Column_header</th>\n      <th>File</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>STATION</td>\n      <td>STATION</td>\n      <td>jfk_weather</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>STATION_NAME</td>\n      <td>STATION_NAME</td>\n      <td>jfk_weather</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ELEVATION</td>\n      <td>ELEVATION</td>\n      <td>jfk_weather</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LATITUDE</td>\n      <td>LATITUDE</td>\n      <td>jfk_weather</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LONGITUDE</td>\n      <td>LONGITUDE</td>\n      <td>jfk_weather</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}, "execution_count": 16, "output_type": "execute_result"}]}, {"metadata": {"id": "c97f45365c154835b5175caa1cd0bee4"}, "cell_type": "code", "source": "pd.set_option('display.max_columns', 2000)\npd.set_option('display.max_rows', 100)\npd.set_option('display.min_rows', 100)\npd.set_option('display.expand_frame_repr', True)\npd.set_option('display.max_colwidth', None)", "execution_count": 17, "outputs": []}, {"metadata": {"id": "7a924718-9d83-43ba-9a66-355dea80798f"}, "cell_type": "markdown", "source": "Join the `df_terms` and `map_terms` dataframes and map each column header to a business term. The code below loops through each file in the catalog and performs the following tasks:\n\n1. Create a dataframe with column headers in the catalog and associated business term and term ids.\n2. Fetch catalog asset id for each csv in the catalog.\n3. Create a column_info attribute for all the files in the catalog.\n4. Map column header to the business terms. "}, {"metadata": {"id": "55bb5ad5-6980-4ecd-89f8-fb25dcdf5512", "scrolled": false}, "cell_type": "code", "source": "\n# For every file in the map terms csv do the following\n# Join the csv with specified file name with the published terms to get its term id\n# drop if any duplicates found to avoid multiple mappings for the same term\n\n#map_terms=map_terms[map_terms['File']==file]\nmap_terms=map_terms.sort_values(by=['File','Column_header'])\nTerms_Headers=pd.merge(map_terms,df_terms,left_on='Business Terms',right_on='metadata.name',how='inner')\nTerms_Headers=Terms_Headers.astype(str).drop_duplicates()\n\nfor file in catalog_asset_ids:#map_terms.File.unique():\n    # Catalog asset id of the particular csvs\n    # for each file name in the map_terms if the csv with this file name exists, get its asset_id from the catalog and use the post request publish create column_info attribute\n    # This column info attribute is necessary to map the busines terms to column to header\n    \n    Terms_Headers_new=Terms_Headers[Terms_Headers.File==file.upper().replace(\".CSV\",\"\")].copy()\n    catalog_asset_id=catalog_asset_ids[file]\n    print(file,  catalog_asset_id)\n    #### \n    payload={\"name\": \"column_info\",\n       \"entity\":{\n                  #\"sample_size\":50\n               }\n    }\n    t=requests.post(host+\"v2/assets/\"+catalog_asset_id+\"/attributes?catalog_id=\"+catalog_id,json=payload,headers=headers,verify=False)\n    #print(t.text)\n    # For each column header in the file map its corresponding business term retrieved from the above join in the dataframe\n\n    i=0\n    for index, rows in Terms_Headers_new.iterrows(): \n        i+=1\n        print(i,rows.Column_header.strip(), \"is mapped to\", rows['Business Terms'])\n        # Create list for the current row \n        # Below payload is used for the patch request to map the  header to business terms\n        payload=[{\"op\":\"add\",\"path\":\"/\"+rows.Column_header.strip(),\"value\":{\"column_terms\":[{\"term_display_name\":rows['Business Terms'],\"term_id\":rows[\"entity.artifacts.global_id\"]}]},\"attribute\":\"column_info\"}]\n    #\n        # Endpoint for patch request\n        url=host+\"v2/assets/\"+catalog_asset_id+\"/attributes/column_info?catalog_id=\"+catalog_id\n    # patch request to map busines terms to column header using term_id\n        patch_attribute=s.patch(url,json=payload,headers=headers,verify=False)\n    #\n        json.loads(patch_attribute.text)", "execution_count": 18, "outputs": [{"name": "stdout", "text": "jfk_weather.csv 2d6e622c-9d85-4798-993a-7a415a54a37d\n", "output_type": "stream"}]}, {"metadata": {"id": "da653c42982e4ca88c2088f17e167b82"}, "cell_type": "code", "source": "!cd /home/wsuser/work && ls", "execution_count": 19, "outputs": []}, {"metadata": {"id": "8a5e5a56-5148-43a4-aa65-e0d8eb9cea21"}, "cell_type": "markdown", "source": "The specified dataset is now published to the catalog and its column headers are mapped to their associated business terms. \n\nNavigate to below path to verify the mappings created above. <br>\n\n**All Catalogs --> New Catalog --> csv file --> any column header from the above list**.\n\nThe associated business term for the column header is displayed."}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}